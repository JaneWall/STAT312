# Tidy Text Mining from STAT 413

```{r setup, include=FALSE, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(tidyverse)
library(tidytext)
library(janeaustenr)
library(stringr)
library(gutenbergr)
library(scales)
```


Learning Objectives

- Remove stop words and identify frequently used words in a text
- Compare word counts between different groups of text

Resources:

[Text Mining with R by Julia Silge and David Robinson](https://www.tidytextmining.com/). 

## Tidy Text Format

This first [video](https://youtu.be/80RHkcE_TIs) corresponds to the online book sections 1.1 - 1.2 which I suggest you read first.

Tidy text format (ttf): A table with one token per row where a token is a meaningful unit of text such as a word, n-gram, sentence or paragraph.

Other text mining tools use:

* strings
* corpus: contain raw strings annotated with metadata
* document-term matrix: sparse matrix with each row containing one document and each column one term or word; entries are generally counts or td-idf (term frequency - inverse document freq)

```{r poemfrag}
text <- c("If You Forget Me",
"by Pablo Neruda",
"I want you to know",
"one thing.",
"You know how this is:",
"if I look",
"at the crystal moon, at the red branch",
"of the slow autumn at my window,",
"if I touch",
"near the fire",
"the impalpable ash",
"or the wrinkled body of the log,",
"everything carries me to you,",
"as if everything that exists,",
"aromas, light, metals,",
"were little boats",
"that sail",
"toward those isles of yours that wait for me."
)
text
text_df <- tibble(
  line = 1:length(text),
  text = text
)
text_df
text_df %>%
  unnest_tokens(word, text)
data(stop_words)
text_word_count <- text_df %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words) %>% # get rid of uninteresting words
  count(word, sort = TRUE) # count of each word left
```

--------------------------------------------

## `unnest_tokens()` on larger text

Section 1.3 in online book.  Then watch this [video](https://youtu.be/qCvyzp7JSOI) as you work through this section.

Let's look at a larger text, say all of Jane Austen's novels.

```{r get_austen}
orig_books <- austen_books() %>%
  group_by(book) %>%
  mutate(linenumber = row_number(),
         chapter = cumsum(str_detect(text, 
             regex("^chapter [\\divxlc]", 
                   ignore_case = TRUE)))) %>%
  ungroup() %>%
  select(chapter, linenumber, everything())
orig_books

#  make data tidy
tidy_books <- orig_books %>%
  unnest_tokens(word, text) %>%
  # use str_extract because some gutenberg texts have other symbols around
  # the words as part of the encoding
  mutate(word = str_extract(word, "[a-z']+")) %>%
  anti_join(stop_words)

tidy_books %>%
  count(word, sort = TRUE)

# visualize
tidy_books %>%
  count(word, sort = TRUE) %>%
  filter(n > 400) %>%
  mutate(word = reorder(word,n)) %>%
  ggplot(aes(word, n)) +
    geom_col() +
    xlab(NULL) +
    coord_flip()
```

----------------------------------------------


## Compare word frequencies between authors

This section corresponds to section 1.4 in the online book. Watch this [video](https://youtu.be/qc7wuH9Dhp0) as you work through this section.

We now compare frequencies across different authors.  We will look at H.G. Wells (The Island of Doctor Moreau, The War of the Worlds, The Time Machine, and The Invisible Man) and the Bronte Sisters (Jane Eyre, Wuthering Heights, Agnes Grey, The Tenant of Wildfell Hall and Villette) since they are from a similar time-frame as Jane Austen.

First, take a few minutes to explore the [gutenberg website](http://www.gutenberg.org/).  We will search by author  and then find the book numbers we want to download.

```{r get_authors}
hgwells <- gutenberg_download(c(35, 36, 159, 5230))
bronte <- gutenberg_download(c(767, 768, 969, 1260, 9182))
tidy_hgwells <- hgwells %>%
  unnest_tokens(word, text) %>%
  mutate(word = str_extract(word, "[a-z']+")) %>%
  anti_join(stop_words)
tidy_bronte <- bronte %>%
  unnest_tokens(word, text) %>%
  mutate(word = str_extract(word, "[a-z']+")) %>%
  anti_join(stop_words)
tidy_hgwells %>%
  count(word, sort = TRUE)
tidy_bronte %>%
  count(word, sort = TRUE)
```
Put all three authors together in one tibble with a new column showing author.
```{r compare_plot}
frequency_by_word_across_authors <- bind_rows(mutate(tidy_bronte,
                 author = "Bronte"),
                 mutate(tidy_hgwells, author = "Wells"),
                 mutate(tidy_books, author = "Austen")) %>%
            mutate(word = str_extract(word, "[a-z']+")) %>%
            count(author, word) %>%
            group_by(author) %>%
            mutate(proportion = n / sum(n)) %>%
            select(-n) %>%
            spread(author, proportion)
frequency_by_word_across_authors
frequency <- frequency_by_word_across_authors %>%
            gather(author, proportion, `Bronte`:`Wells`)
frequency
```

------------------------------------

## Compare word frequency by author to Austen

Book sections 1.5 - 1.6 and this [video](https://youtu.be/vvmoHPM1Yf0)

Now let's graph the frequency comparison of each other author to Jane Austen.  
```{r compare}
frequency %>% ggplot(aes(x = proportion, 
          y = `Austen`, 
          color = abs(`Austen` - proportion))) +
  geom_abline(color = "gray40", lty = 2) +
  geom_jitter(alpha = 0.1, size = 2.5, 
              width = 0.3, height = 0.3) +
  geom_text(aes(label = word), 
            check_overlap = TRUE, vjust = 1.5) +
  scale_x_log10(labels = percent_format()) +
  scale_y_log10(labels = percent_format()) +
  scale_color_gradient(limits = c(0, 0.001), 
                       low = "darkslategray4",
                       high = "gray75") +
  facet_wrap(~author, ncol = 2) +
  theme(legend.position="none") +
  labs(y = "Jane Austen", x = NULL)
```
We can tell that Austen and Bronte are more similar (grouped closer to the line) than Austen and Wells.  Let's use a correlation test to quantify the amounts.
```{r cor_test}
df_Bronte <- frequency[frequency$author == "Bronte",]
df_Bronte
cor.test(data = df_Bronte,  ~ proportion + `Austen`)
df_Wells <- frequency[frequency$author == "Wells",]
df_Wells
cor.test(data = df_Wells,  ~ proportion + `Austen`)
```
- **Exercise 1:**  Repeat the above analysis using all the H.G. Wells and Bronte works that are available on gutenberg.org

You will need to use gutenberg_works(author == "Wells, H. G. (Herbert George)") to get started. We figured this out by looking at any H.G. Wells book on the gutenberg.org website and then looking at the Bibiliography Record to see how the author is listed there. Similarly, find the Bronte works.

- **Exercise 2:** Pick three other authors from Gutenberg.org and download their works. Compare the authors.  Which two are more alike?  Some suggestions if you can't think of any:  Mark Twain, Leo Tolstoy, Charles Dickens.

```{r exercise1, echo = FALSE}
wells <- gutenberg_works(author == "Wells, H. G. (Herbert George)")
# wells <- wells %>% filter(!is.na(gutenberg_bookshelf))
hgwells <- gutenberg_download(wells$gutenberg_id)
# bronte <- gutenberg_works(author == "Brontë, Anne")
# bronte2 <- gutenberg_works(author == "Brontë, Charlotte")
# bronte3 <- gutenberg_works(author == "Brontë, Emily")
# bronte <- bronte %>%
#   bind_rows(bronte2) %>% 
#   bind_rows(bronte3)
bronte <- gutenberg_works(author %in% 
                            c("Brontë, Emily","Brontë, Charlotte", "Brontë, Anne" ))

# bronte <- bronte %>% filter(!is.na(gutenberg_bookshelf))
bronte <- gutenberg_download(bronte$gutenberg_id)
tidy_hgwells <- hgwells %>%
  unnest_tokens(word, text) %>%
  mutate(word = str_extract(word, "[a-z']+")) %>%
  anti_join(stop_words)
tidy_bronte <- bronte %>%
  unnest_tokens(word, text) %>%
  mutate(word = str_extract(word, "[a-z']+")) %>%
  anti_join(stop_words)
frequency_by_word_across_authors <- bind_rows(mutate(tidy_bronte,
                 author = "Bronte"),
                 mutate(tidy_hgwells, author = "Wells"),
                 mutate(tidy_books, author = "Austen")) %>%
            mutate(word = str_extract(word, "[a-z']+")) %>%
            count(author, word) %>%
            group_by(author) %>%
            mutate(proportion = n / sum(n)) %>%
            select(-n) %>%
            spread(author, proportion)
frequency_by_word_across_authors
frequency <- frequency_by_word_across_authors %>%
            gather(author, proportion, `Bronte`:`Wells`)
frequency
frequency %>% ggplot(aes(x = proportion, 
          y = `Austen`, 
          color = abs(`Austen` - proportion))) +
  geom_abline(color = "gray40", lty = 2) +
  geom_jitter(alpha = 0.1, size = 2.5, 
              width = 0.3, height = 0.3) +
  geom_text(aes(label = word), 
            check_overlap = TRUE, vjust = 1.5) +
  scale_x_log10(labels = percent_format()) +
  scale_y_log10(labels = percent_format()) +
  scale_color_gradient(limits = c(0, 0.001), 
                       low = "darkslategray4",
                       high = "gray75") +
  facet_wrap(~author, ncol = 2) +
  theme(legend.position="none") +
  labs(y = "Jane Austen", x = NULL)
df_Bronte <- frequency[frequency$author == "Bronte",]
df_Bronte
cor.test(data = df_Bronte,  ~ proportion + `Austen`)
df_Wells <- frequency[frequency$author == "Wells",]
df_Wells
cor.test(data = df_Wells,  ~ proportion + `Austen`)
```
 

